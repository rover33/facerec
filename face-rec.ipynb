{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a reference to webcam #0 (the default one)\n",
    "video_capture = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample picture and learn how to recognize it.\n",
    "remy_image = face_recognition.load_image_file(\"remy.jpg\")\n",
    "remy_face_encoding = face_recognition.face_encodings(remy_image)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.74583465e-02 -6.60402998e-02  2.42562983e-02 -9.65260807e-03\n",
      " -3.89938056e-02 -3.64935920e-02  5.52540570e-02 -2.78785434e-02\n",
      "  1.61573842e-01 -2.15796549e-02  2.19327658e-01 -2.46821065e-03\n",
      " -2.17961907e-01 -4.52499427e-02 -7.81779438e-02  2.72037834e-02\n",
      " -1.40940562e-01 -9.95025560e-02 -4.22619209e-02 -1.03104256e-01\n",
      "  6.52135760e-02  1.26903672e-02 -1.84537526e-02 -4.66367379e-02\n",
      " -1.56566560e-01 -3.11120033e-01 -1.37378201e-01 -1.78490788e-01\n",
      "  2.13636160e-02 -4.11714129e-02  1.05857618e-01  5.76869212e-02\n",
      " -8.66422132e-02 -9.99242440e-03  5.55143207e-02  1.14922952e-02\n",
      "  1.73792476e-04 -4.81524467e-02  1.97116673e-01  2.65083909e-02\n",
      " -9.75823626e-02 -1.78871397e-03  8.28818232e-02  2.98181534e-01\n",
      "  9.45829228e-02  1.05857320e-01  7.91583769e-03 -3.55920792e-02\n",
      "  9.93830934e-02 -2.43011057e-01  9.10205841e-02  1.88409612e-01\n",
      "  5.93509525e-02  7.63706863e-02  1.60760656e-01 -1.34464845e-01\n",
      "  5.06507196e-02  9.46052521e-02 -2.32672408e-01  1.00808203e-01\n",
      "  4.33401391e-02  8.68024305e-02  1.39190275e-02 -7.62840807e-02\n",
      "  1.71939284e-01  8.19595382e-02 -1.44750178e-01 -5.83706424e-02\n",
      "  1.21209249e-01 -2.04210162e-01 -2.49951519e-02  4.00868580e-02\n",
      " -1.61071837e-01 -2.07948953e-01 -1.90636575e-01  4.71988320e-02\n",
      "  4.43409503e-01  1.91874489e-01 -4.61527519e-02  2.77061556e-02\n",
      " -1.05996698e-01 -5.39568253e-02  6.91911951e-02 -2.82887723e-02\n",
      " -9.69639122e-02  1.07048154e-02 -6.73631206e-02  5.92014566e-03\n",
      "  1.55559942e-01  4.00721878e-02 -2.92733293e-02  2.05216214e-01\n",
      " -6.37599602e-02 -1.85996480e-02 -1.24153933e-02 -1.26248123e-02\n",
      " -9.56437886e-02  8.93231109e-03 -6.56049177e-02 -1.38685415e-02\n",
      "  1.02223409e-02 -1.23622179e-01  6.33191913e-02  6.27352670e-02\n",
      " -1.97948962e-01  9.71611515e-02 -1.67411845e-02 -5.81414718e-03\n",
      " -3.48195806e-02  3.53622958e-02 -1.22057565e-01  5.08572459e-02\n",
      "  1.67283520e-01 -2.82351345e-01  1.97665200e-01  1.41768351e-01\n",
      "  7.11273998e-02  1.25620022e-01  3.54772136e-02  6.51733484e-03\n",
      " -5.73871434e-02 -5.69159128e-02 -1.60972401e-01 -5.70362955e-02\n",
      " -7.99622163e-02 -1.31954830e-02  2.52982173e-02  2.28734389e-02]\n"
     ]
    }
   ],
   "source": [
    "print(remy_face_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cody_image = face_recognition.load_image_file(\"cody.jpg\")\n",
    "cody_face_encoding = face_recognition.face_encodings(cody_image)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "taylor_image = face_recognition.load_image_file(\"taylor.jpg\")\n",
    "taylor_face_encoding = face_recognition.face_encodings(taylor_image)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create arrays of known face encodings and their names\n",
    "known_face_encodings = [\n",
    "    remy_face_encoding,\n",
    "    cody_face_encoding,\n",
    "    taylor_face_encoding\n",
    "]\n",
    "known_face_names = [\n",
    "    \"Remy\",\n",
    "    \"Cody\",\n",
    "    \"taylor\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.15263328e-03  1.07421115e-01  2.11272333e-02 -4.10189442e-02\n",
      " -1.35224670e-01  3.02238241e-02 -7.52124339e-02 -1.01473089e-02\n",
      "  2.30083629e-01 -3.04139331e-02  2.04139709e-01  4.49312031e-02\n",
      " -3.26619655e-01  1.91239305e-02 -6.15920573e-02  1.12495199e-01\n",
      " -2.27479130e-01 -4.71524559e-02 -7.00758100e-02 -7.94766918e-02\n",
      "  9.95257050e-02  1.06244929e-01  9.14436653e-02  1.97496172e-02\n",
      " -1.03642426e-01 -3.79210442e-01 -9.85681713e-02 -9.59089696e-02\n",
      "  9.83978137e-02 -1.61637172e-01  1.25847133e-02 -1.08352368e-04\n",
      " -1.40913442e-01 -1.58359744e-02  8.58172961e-03  3.06643825e-02\n",
      " -2.50899792e-02 -1.39891386e-01  2.17190266e-01  7.27810860e-02\n",
      " -1.64086744e-01  1.63341239e-02 -1.50181614e-02  2.36148730e-01\n",
      "  1.24549493e-01  8.14079270e-02  4.08306643e-02 -1.02127157e-01\n",
      "  1.10652424e-01 -2.16367275e-01  1.06705777e-01  2.17850804e-01\n",
      "  1.23370312e-01  2.38958746e-02  3.41554172e-02 -1.52273446e-01\n",
      "  2.03637872e-02  2.12212950e-01 -2.38599762e-01  7.93558061e-02\n",
      "  1.37047455e-01 -1.02101259e-01 -2.68009119e-02 -6.24426454e-02\n",
      "  2.12854058e-01  8.11098963e-02 -1.66276842e-01 -8.04449394e-02\n",
      "  7.81665444e-02 -1.51091188e-01 -6.50032088e-02  1.04669342e-02\n",
      " -1.20977014e-01 -1.77951768e-01 -2.84454823e-01  5.91221042e-02\n",
      "  3.48256171e-01  1.18044533e-01 -1.39612556e-01  6.46150112e-03\n",
      " -6.51015863e-02  1.34906452e-02 -5.74254338e-03  1.23503260e-01\n",
      " -1.89623088e-01 -1.72749460e-02 -1.19262837e-01  4.70968634e-02\n",
      "  1.38943702e-01 -3.07498313e-03  2.30025267e-03  2.80530006e-01\n",
      " -7.44792260e-03  6.20537400e-02  1.08086746e-02  6.20048642e-02\n",
      " -1.48361698e-01 -6.79357424e-02 -1.82902794e-02  1.86501872e-02\n",
      "  7.47889355e-02 -1.51329473e-01 -2.41969079e-02  7.19418228e-02\n",
      " -2.03141764e-01  1.07991382e-01 -6.06604815e-02 -6.94481060e-02\n",
      "  6.03337660e-02 -6.99167624e-02 -1.06974795e-01 -5.58319651e-02\n",
      "  2.23965764e-01 -2.74368852e-01  2.03250796e-01  1.94311917e-01\n",
      "  7.36550689e-02  1.87323064e-01  7.79205635e-02  1.29023001e-01\n",
      " -6.16942979e-02 -6.25807717e-02 -1.87329948e-01 -7.03470409e-02\n",
      "  5.65134920e-02 -5.74147068e-02  6.05836585e-02 -3.42048379e-03]\n"
     ]
    }
   ],
   "source": [
    "print(cody_face_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_cap():\n",
    "    # Initialize some variables\n",
    "    face_locations = []\n",
    "    face_encodings = []\n",
    "    face_names = []\n",
    "    process_this_frame = True\n",
    "    while True:\n",
    "        # Grab a single frame of video\n",
    "        ret, frame = video_capture.read()\n",
    "\n",
    "        # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "        # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "        rgb_small_frame = small_frame[:, :, ::-1]\n",
    "\n",
    "        # Only process every other frame of video to save time\n",
    "        if process_this_frame:\n",
    "            # Find all the faces and face encodings in the current frame of video\n",
    "            face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "            face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "            face_names = []\n",
    "            if len(face_encodings) > 0:\n",
    "                for face_encoding in face_encodings:\n",
    "                    # See if the face is a match for the known face(s)\n",
    "                    matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "                    name = \"Unknown\"\n",
    "\n",
    "                    # # If a match was found in known_face_encodings, just use the first one.\n",
    "                    # if True in matches:\n",
    "                    #     first_match_index = matches.index(True)\n",
    "                    #     name = known_face_names[first_match_index]\n",
    "\n",
    "                    # Or instead, use the known face with the smallest distance to the new face\n",
    "                    face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "                    best_match_index = np.argmin(face_distances)\n",
    "                    if matches[best_match_index]:\n",
    "                        name = known_face_names[best_match_index]\n",
    "\n",
    "                    face_names.append(name)\n",
    "\n",
    "        process_this_frame = not process_this_frame\n",
    "\n",
    "\n",
    "        # Display the results\n",
    "        for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "            # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "            top *= 4\n",
    "            right *= 4\n",
    "            bottom *= 4\n",
    "            left *= 4\n",
    "\n",
    "            # Draw a box around the face\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "            # Draw a label with a name below the face\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "        # Display the resulting image\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        # Hit 'q' on the keyboard to quit!\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release handle to the webcam\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_cap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
